import glob
import os
import time
import math, random

import streamlit as st
import pandas as pd
import numpy as np
import torch

# --- ä»é¡¹ç›®ä¸­å¯¼å…¥å¿…è¦çš„æ¨¡å— ---
# ç¡®ä¿ config.py åœ¨åŒä¸€ç›®å½•æˆ–å¯é€šè¿‡ PYTHONPATH è®¿é—®
from config import config, model_config
from Loader.SeriesLoader import TimeSeriesDataset
from utils.predictior import ModelInference

# --- åº”ç”¨é…ç½® ---
st.set_page_config(page_title="ç®¡é“çŠ¶æ€é¢„æµ‹æ¨¡æ‹Ÿ", layout="centered")

MODEL_PATH = "FFTbest_classification_model.pth"
CLASS_NAMES = ["CC", "GL", "LC", "OL", "NL"]
NUM_PIPELINES = 3  # æˆ‘ä»¬å°†æ¨¡æ‹Ÿçš„ç®¡é“æ•°é‡

# --- æ ¸å¿ƒæ¨¡æ‹Ÿå‚æ•° ---
# æ¯ä¸ªæ•°æ®å—çš„å¤§å° (0.01s çš„æ•°æ®)
CHUNK_SIZE = config.get("window_size", 256) 
# æ¯ä¸ªæ•°æ®å—åˆ°è¾¾çš„é—´éš”æ—¶é—´ï¼ˆç§’ï¼‰
CHUNK_UPDATE_INTERVAL_SECONDS = 0.2 # å¯ä»¥åŠ å¿«æ¨¡æ‹Ÿé€Ÿåº¦

# --- å…³é”®å‡½æ•° ---

@st.cache_resource
def load_model_and_data():
    """
    åŠ è½½é¢„è®­ç»ƒæ¨¡å‹å’Œæ ·æœ¬æ•°æ®ã€‚æ­¤å‡½æ•°è¢«ç¼“å­˜ä»¥æé«˜æ€§èƒ½ã€‚
    """
    try:
        predictor = ModelInference(
            model_path=MODEL_PATH,
            config=config,
            model_config=model_config,
            class_names=CLASS_NAMES
        )
    except Exception as e:
        st.error(f"åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
        st.error(f"è¯·ç¡®ä¿ '{MODEL_PATH}' åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸” 'config.py' é…ç½®æ­£ç¡®ã€‚")
        return None, None, None

    try:
        data_dir = config["data_dir"]
        file_pattern = config["file_pattern"]
        file_paths = sorted(glob.glob(os.path.join(data_dir, file_pattern)))
        if not file_paths:
            st.error(f"åœ¨ '{data_dir}' ä¸­æœªæ‰¾åˆ°åŒ¹é… '{file_pattern}' çš„æ–‡ä»¶ã€‚")
            return predictor, None

        all_dataframes = []
        for file_path in file_paths:
            df = pd.read_csv(file_path)
            all_dataframes.append(df)

    except Exception as e:
        st.error(f"è¯»å–æ•°æ®å¤±è´¥: {e}")
        return predictor, None

    try:
        if len(all_dataframes) < NUM_PIPELINES:
            st.warning(f"æ•°æ®æ–‡ä»¶ä¸è¶³ {NUM_PIPELINES} ä¸ªï¼Œå°†ä½¿ç”¨æ‰€æœ‰å¯ç”¨æ–‡ä»¶ã€‚")
            selected_indices = list(range(len(all_dataframes)))
        else:
            selected_indices = random.sample(range(len(all_dataframes)), NUM_PIPELINES)

        pipeline_data = [all_dataframes[idx] for idx in selected_indices]

    except Exception as e:
        st.error(f"æ ·æœ¬é€‰æ‹©å¤±è´¥: {e}")
        return predictor, None

    return predictor, pipeline_data

# --- Streamlit åº”ç”¨ä¸»é€»è¾‘ ---

# 1. åŠ è½½æ¨¡å‹å’Œæ•°æ® (åªè¿è¡Œä¸€æ¬¡)
predictor, pipeline_data = load_model_and_data()
if not predictor or not pipeline_data:
    st.stop()

# 2. åˆå§‹åŒ–ä¼šè¯çŠ¶æ€ (Session State)
if 'selected_pipeline_index' not in st.session_state:
    st.session_state.selected_pipeline_index = 0
if 'correct_predictions' not in st.session_state:
    st.session_state.correct_predictions = 0
if 'total_predictions' not in st.session_state:
    st.session_state.total_predictions = 0

# 3. ä¾§è¾¹æ ï¼šç”¨äºé€‰æ‹©ç®¡é“
with st.sidebar:
    st.header("ç®¡é“æ§åˆ¶é¢æ¿")
    pipeline_names = [f"Pipeline {i+1}" for i in range(len(pipeline_data))]

    # å½“ç”¨æˆ·ç‚¹å‡»ä¸åŒçš„ç®¡é“æ—¶ï¼Œæ›´æ–°ä¼šè¯çŠ¶æ€å¹¶é‡ç½®æ¨¡æ‹Ÿ
    for i, name in enumerate(pipeline_names):
        if st.button(name, key=f"pipe_{i}"):
            if st.session_state.selected_pipeline_index != i:
                st.session_state.selected_pipeline_index = i
                # é‡ç½®å‡†ç¡®ç‡è®¡æ•°å™¨
                st.session_state.correct_predictions = 0
                st.session_state.total_predictions = 0
                st.rerun()

# --- 4. ä¸»ç•Œé¢å¸ƒå±€å’Œæ¨¡æ‹Ÿ ---

# è·å–å½“å‰é€‰æ‹©çš„ç®¡é“æ•°æ®
selected_idx = st.session_state.selected_pipeline_index
selected_df = pipeline_data[selected_idx]

# æå–çœŸå®æ ‡ç­¾å’Œç‰¹å¾æ•°æ®
target_col = config["target_col"]
feature_cols_names = [col for col in selected_df.columns if col != target_col and col not in config.get("delete_col", [])]

true_label_idx = selected_df[target_col].iloc[0]
true_label = CLASS_NAMES[true_label_idx]
full_df = selected_df[feature_cols_names]
max_timestep = len(full_df)
total_chunks = math.ceil(max_timestep / CHUNK_SIZE)


st.title(f"ç®¡é“ {selected_idx + 1} çŠ¶æ€é¢„æµ‹æ¨¡æ‹Ÿ")
st.markdown("---")

# --- 5. åˆ›å»ºç”¨äºåŠ¨æ€æ›´æ–°çš„å ä½ç¬¦ ---
status_placeholder = st.empty()
accuracy_placeholder = st.empty()
result_placeholder = st.empty()

# --- 6. å®æ—¶æ¨¡æ‹Ÿå¾ªç¯ ---
# æŒ‰ CHUNK_SIZE æ­¥é•¿è¿›è¡Œè¿­ä»£
for i in range(total_chunks):
    start_idx = i * CHUNK_SIZE
    end_idx = start_idx + CHUNK_SIZE
    
    # è·å–å½“å‰æ•°æ®å—
    chunk_df = full_df.iloc[start_idx:end_idx]

    # å¦‚æœæ•°æ®å—å°äºçª—å£å¤§å°ï¼Œåˆ™è·³è¿‡ï¼ˆé€šå¸¸æ˜¯æœ€åä¸€ä¸ªå—ï¼‰
    if len(chunk_df) < CHUNK_SIZE:
        continue
    
    # ä½¿ç”¨å½“å‰æ•°æ®å—è¿›è¡Œé¢„æµ‹
    predicted_label = predictor.predict(chunk_df)

    # æ›´æ–°å‡†ç¡®ç‡è®¡æ•°å™¨
    st.session_state.total_predictions += 1
    if predicted_label == true_label:
        st.session_state.correct_predictions += 1
    
    # --- æ›´æ–°ç•Œé¢å…ƒç´  ---
    status_text = "ğŸŸ¢ **æ¨¡æ‹Ÿè¿›è¡Œä¸­...**" if i < total_chunks - 1 else "ğŸ **æ¨¡æ‹Ÿå®Œæˆ!**"
    status_placeholder.header(f"{status_text}")
    status_placeholder.progress((i + 1) / total_chunks, text=f"å·²å¤„ç†æ•°æ®å—: {i + 1} / {total_chunks}")

    # æ›´æ–°å‡†ç¡®ç‡æ˜¾ç¤º
    correct = st.session_state.correct_predictions
    total = st.session_state.total_predictions
    accuracy = (correct / total) * 100 if total > 0 else 0
    
    with accuracy_placeholder.container():
        st.metric(label="**å®æ—¶é¢„æµ‹å‡†ç¡®ç‡**", value=f"{accuracy:.2f} %", delta=f"{correct} / {total} æ­£ç¡®")

    # æ›´æ–°æœ€æ–°çš„é¢„æµ‹ç»“æœ
    with result_placeholder.container():
        st.subheader("æœ€æ–°é¢„æµ‹ç»“æœ")
        col_pred, col_true = st.columns(2)
        with col_pred:
            st.write("**æ¨¡å‹é¢„æµ‹:**")
            if predicted_label == true_label:
                st.success(f"âœ”ï¸ {predicted_label}")
            else:
                st.error(f"âŒ {predicted_label}")
        with col_true:
            st.write("**çœŸå®çŠ¶æ€:**")
            st.info(f"â„¹ï¸ {true_label}")
        
        st.write("**ç”¨äºæœ¬æ¬¡é¢„æµ‹çš„æ•°æ®å— (æœ€å5è¡Œ):**")
        st.dataframe(chunk_df.tail(5))


    # æ§åˆ¶æ¨¡æ‹Ÿé€Ÿåº¦
    time.sleep(CHUNK_UPDATE_INTERVAL_SECONDS)

# å¾ªç¯ç»“æŸåï¼Œç¡®ä¿æœ€ç»ˆçŠ¶æ€å¯è§
total = st.session_state.total_predictions
if total == 0:
    st.warning("æ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®æ¥ç”Ÿæˆä»»ä½•é¢„æµ‹ã€‚")
else:
    status_placeholder.header("ğŸ **æ¨¡æ‹Ÿå®Œæˆ!**")