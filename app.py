import streamlit as st
import torch
import time
import os
import glob
import random
import pandas as pd
import altair as alt

# ç¡®ä¿å¯¼å…¥äº† dataset_config
from config import config, model_config, dataset_config 
from Loader.SeriesLoader import TimeSeriesDataset
from utils.predictior import ModelInference

# é¡µé¢é…ç½®
st.set_page_config(page_title="å¤šç®¡é“æ»‘çª—æ¨¡æ‹Ÿ (v7)", layout="centered")

MODEL_PATH = "FFTbest_classification_model.pth"
CLASS_NAMES = ["CC", "GL", "LC", "OL", "NL"]
NUM_PIPELINES = 100 # æœ€å¤šæ¨¡æ‹Ÿçš„ç®¡é“æ•°é‡
SIMULATION_INTERVAL_SECONDS = 0.01 # æ¯æ¬¡æ»‘çª—å¤„ç†ä¹‹é—´åœé¡¿æ—¶é—´ï¼Œ0ä¸ºæ— åœé¡¿ï¼Œå¯ä»¥è°ƒå¤§è§‚å¯Ÿæ•ˆæœ

@st.cache_resource
def load_resources():
    """
    åŠ è½½æ¨¡å‹å’Œå‡†å¤‡æ•°æ®é›†ï¼Œä½¿ç”¨ @st.cache_resource ç¼“å­˜ï¼Œé¿å…æ¯æ¬¡é¡µé¢åˆ·æ–°éƒ½é‡æ–°åŠ è½½ã€‚
    """
    # è·å–æ•°æ®ç›¸å…³çš„é…ç½®ï¼Œè¿™é‡Œç»Ÿä¸€ä» dataset_config["Data"] è·å–
    data_cfg = dataset_config["Data"]

    try:
        # åˆå§‹åŒ–æ¨¡å‹æ¨ç†å™¨ï¼Œä¼ å…¥æ­£ç¡®çš„ data_config
        predictor = ModelInference(
            model_path=MODEL_PATH,
            config=config, # ä¸»é…ç½®
            data_config=data_cfg, # æ•°æ®é›†é…ç½®
            model_config=model_config,
            class_names=CLASS_NAMES
        )
    except Exception as e:
        st.error(f"åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
        return None, None

    try:
        # è·å–æ‰€æœ‰ç¬¦åˆæ–‡ä»¶æ¨¡å¼çš„CSVæ–‡ä»¶è·¯å¾„
        all_file_paths = sorted(glob.glob(os.path.join(data_cfg["data_dir"], data_cfg["file_pattern"])))
        if not all_file_paths:
            st.error(f"æ‰¾ä¸åˆ°æ–‡ä»¶: {data_cfg['file_pattern']} åœ¨ {data_cfg['data_dir']} ä¸­ã€‚è¯·æ£€æŸ¥è·¯å¾„å’Œæ–‡ä»¶æ¨¡å¼ã€‚")
            return predictor, None

        # éšæœºé€‰æ‹©æˆ–å…¨éƒ¨é€‰æ‹©è¦æ¨¡æ‹Ÿçš„ç®¡é“
        paths_to_simulate = all_file_paths if len(all_file_paths) <= NUM_PIPELINES else random.sample(all_file_paths, NUM_PIPELINES)
        
        # è®¡ç®—é‡‡æ ·ç‚¹æ•°çš„çª—å£å¤§å°å’Œæ­¥é•¿
        # config["window_size"] å’Œ config["stride"] æ˜¯ä»¥ç§’ä¸ºå•ä½çš„ï¼Œéœ€è¦ä¹˜ä»¥é¢‘ç‡è½¬æ¢ä¸ºé‡‡æ ·ç‚¹æ•°
        window_size_samples = int(config["freq"] * config["window_size"])
        stride_samples = int(config["freq"] * config["stride"])

        pipeline_info = []
        for path in paths_to_simulate:
            data_dir = os.path.dirname(path)
            file_pattern_single = os.path.basename(path) # åªå¤„ç†å•ä¸ªæ–‡ä»¶ï¼Œæ‰€ä»¥æ¨¡å¼å°±æ˜¯æ–‡ä»¶å

            # åˆå§‹åŒ–TimeSeriesDatasetï¼Œä¼ å…¥é‡‡æ ·ç‚¹æ•°çš„çª—å£å¤§å°å’Œæ­¥é•¿
            # ç¡®ä¿ä¼ å…¥æ­£ç¡®çš„ Normalization, delete_col, constant_col, target_col
            dataset = TimeSeriesDataset(
                data_dir=data_dir,
                file_pattern=file_pattern_single, # ä¼ é€’å•ä¸ªæ–‡ä»¶åä½œä¸ºæ¨¡å¼
                window_size=window_size_samples, # ä½¿ç”¨è®¡ç®—å‡ºçš„é‡‡æ ·ç‚¹æ•°
                stride=stride_samples,       # ä½¿ç”¨è®¡ç®—å‡ºçš„é‡‡æ ·ç‚¹æ•°
                target_col=data_cfg["target_col"],
                Normalization=data_cfg.get("Normalization", True),
                delete_col=data_cfg["delete_col"],
                constant_col=data_cfg["constant_col"],
                # freq å‚æ•°ä¸éœ€è¦ä¼ é€’ç»™ datasetï¼Œå› ä¸º window_size å’Œ stride å·²ç»è½¬æ¢ä¸ºé‡‡æ ·ç‚¹æ•°
            )

            # ç¡®ä¿æ•°æ®é›†ä¸­æœ‰æ ·æœ¬
            if len(dataset) > 0:
                # è·å–ç¬¬ä¸€ä¸ªæ ·æœ¬çš„çœŸå®æ ‡ç­¾ï¼ˆå‡è®¾æ‰€æœ‰æ ·æœ¬çš„æ ‡ç­¾ç›¸åŒï¼‰
                _, label_tensor = dataset[0] 
                df_raw = pd.read_csv(path)
                pipeline_info.append({
                    'path': file_pattern_single,
                    'dataset': dataset,
                    'num_samples': len(dataset),
                    'true_label_idx': label_tensor.item(),
                    'raw_df': df_raw.reset_index(drop=True)
                })
            else:
                st.warning(f"æ–‡ä»¶ '{file_pattern_single}' ä¸­æ²¡æœ‰æœ‰æ•ˆæ ·æœ¬ç”Ÿæˆï¼Œå·²è·³è¿‡ã€‚")


        if not pipeline_info:
            st.error("æ— æ³•ä»é€‰å®šçš„æ–‡ä»¶ä¸­ç”Ÿæˆä»»ä½•æœ‰æ•ˆæ ·æœ¬ã€‚è¯·æ£€æŸ¥æ•°æ®ã€‚")
            return predictor, None

        return predictor, pipeline_info

    except Exception as e:
        st.error(f"æ•°æ®å¤„ç†å‡ºé”™: {e}")
        return predictor, None

# ä¸»é€»è¾‘å¼€å§‹
predictor, pipeline_info = load_resources()
if not predictor or not pipeline_info:
    st.stop() # å¦‚æœåŠ è½½å¤±è´¥ï¼Œåœæ­¢æ‰§è¡Œ

# è·å–ç‰¹å¾åˆ—åç§°ï¼Œç”¨äºç»˜å›¾
# è¿™äº›åˆ—åœ¨ ModelInference ä¸­å·²ç»è®¡ç®—å¥½ï¼Œå¯ä»¥ç›´æ¥ä» predictor å¯¹è±¡ä¸­è·å–
feature_cols_for_plot = predictor.feature_cols_names

# ä¼šè¯çŠ¶æ€ï¼Œç”¨äºå­˜å‚¨è·¨ reruns çš„æ•°æ®
if 'selected_pipeline_index' not in st.session_state:
    st.session_state.selected_pipeline_index = 0
if 'correct_predictions' not in st.session_state:
    st.session_state.correct_predictions = 0
if 'total_predictions' not in st.session_state:
    st.session_state.total_predictions = 0

# ä¾§è¾¹æ ï¼šç®¡é“é€‰æ‹©
with st.sidebar:
    st.header("åˆ‡æ¢ç®¡é“")
    # éå†æ‰€æœ‰åŠ è½½çš„ç®¡é“ä¿¡æ¯ï¼Œåˆ›å»ºæŒ‰é’®
    for i, info in enumerate(pipeline_info):
        # æ˜¾ç¤ºæ–‡ä»¶åçš„æœ€åä¸€éƒ¨åˆ†ï¼Œæ›´ç®€æ´
        display_name = info['path'].split('_')[-1].replace('.csv', '') 
        name = f"ç®¡é“ {i+1} ({display_name})"
        if st.button(name, key=f"pipe_{i}"):
            st.session_state.selected_pipeline_index = i
            st.session_state.correct_predictions = 0 # åˆ‡æ¢ç®¡é“æ—¶é‡ç½®ç»Ÿè®¡
            st.session_state.total_predictions = 0
            st.rerun() # é‡æ–°è¿è¡Œåº”ç”¨ä»¥åŠ è½½æ–°ç®¡é“çš„æ•°æ®

# è·å–å½“å‰é€‰å®šçš„ç®¡é“ä¿¡æ¯
idx = st.session_state.selected_pipeline_index
current = pipeline_info[idx]
dataset = current["dataset"]
true_label = CLASS_NAMES[current["true_label_idx"]]
total_samples = current["num_samples"]
df_raw = current["raw_df"]

# ä»é…ç½®ä¸­è·å–ä»¥é‡‡æ ·ç‚¹ä¸ºå•ä½çš„çª—å£å¤§å°å’Œæ­¥é•¿ï¼Œç”¨äºè®¡ç®—ç»˜å›¾èŒƒå›´
window_size_samples = int(config["freq"] * config["window_size"])
stride_samples = int(config["freq"] * config["stride"])

# ä¸»ç•Œé¢ä¿¡æ¯
st.title(f"å½“å‰ç®¡é“: {current['path']}")
st.markdown(f"**çœŸå®æ ‡ç­¾:** `{true_label}` | **æ€»æ ·æœ¬æ•° (æ»‘çª—):** `{total_samples}`")
st.markdown("---")

# åˆ›å»ºå ä½ç¬¦ï¼Œä»¥ä¾¿åœ¨å¾ªç¯ä¸­åŠ¨æ€æ›´æ–°UIå…ƒç´ 
status_placeholder = st.empty()
accuracy_placeholder = st.empty()
result_placeholder = st.empty()
plot_placeholder = st.empty()

# æ¨¡æ‹Ÿä¸»å¾ªç¯ï¼šéå†æ•°æ®é›†ä¸­çš„æ¯ä¸ªæ»‘çª—æ ·æœ¬
for i, (inputs_tensor, _) in enumerate(dataset):
    # æ¨¡å‹é¢„æµ‹
    # inputs_tensor çš„å½¢çŠ¶æ˜¯ [window_size, num_features]
    # æ¨¡å‹æœŸæœ›çš„è¾“å…¥æ˜¯ [batch_size, window_size, num_features]ï¼Œæ‰€ä»¥éœ€è¦ unsqueeze(0)
    inputs_tensor = inputs_tensor.unsqueeze(0).to(predictor.device) 
    
    with torch.no_grad(): # æ¨ç†æ¨¡å¼ï¼Œæ— éœ€è®¡ç®—æ¢¯åº¦
        outputs = predictor.model(inputs_tensor)

    # è·å–é¢„æµ‹ç»“æœ
    _, predicted_idx = torch.max(outputs.data, 1)
    predicted_label = predictor.class_names[predicted_idx.item()]

    # æ›´æ–°ç»Ÿè®¡æ•°æ®
    st.session_state.total_predictions += 1
    if predicted_label == true_label:
        st.session_state.correct_predictions += 1

    # æ›´æ–°ç•Œé¢çŠ¶æ€
    status_text = "ğŸŸ¢ æ­£åœ¨æ¨¡æ‹Ÿ..." if i < total_samples - 1 else "ğŸ æ¨¡æ‹Ÿå®Œæˆ"
    status_placeholder.header(status_text)
    status_placeholder.progress((i + 1) / total_samples, text=f"å¤„ç†æ ·æœ¬: {i + 1} / {total_samples}")

    # æ˜¾ç¤ºå½“å‰å‡†ç¡®ç‡
    acc = st.session_state.correct_predictions / st.session_state.total_predictions * 100
    with accuracy_placeholder.container():
        st.metric("å½“å‰å‡†ç¡®ç‡", f"{acc:.2f} %", f"{st.session_state.correct_predictions} / {st.session_state.total_predictions}")

    # æ˜¾ç¤ºå½“å‰é¢„æµ‹ç»“æœ
    with result_placeholder.container():
        st.subheader("å½“å‰é¢„æµ‹")
        col1, col2 = st.columns(2)
        with col1:
            st.write("é¢„æµ‹")
            if predicted_label == true_label:
                st.success(f"âœ”ï¸ {predicted_label}")
            else:
                st.error(f"âŒ {predicted_label}") # ä½¿ç”¨ st.error è¡¨ç¤ºé”™è¯¯é¢„æµ‹
        with col2:
            st.write("çœŸå®")
            st.info(f"â„¹ï¸ {true_label}")

    # å±•ç¤ºåŸå§‹æ•°æ® Â±2 çª—å£å†…å®¹ï¼Œç”¨äºä¸Šä¸‹æ–‡æŸ¥çœ‹
    # å½“å‰çª—å£çš„èµ·å§‹é‡‡æ ·ç‚¹
    current_window_start_idx = i * stride_samples 
    # æ‰©å¤§èŒƒå›´ï¼šå½“å‰çª—å£å‰2ä¸ªçª—å£åˆ°å2ä¸ªçª—å£
    plot_start_idx = current_window_start_idx - 2 * window_size_samples
    plot_end_idx = current_window_start_idx + 3 * window_size_samples # 3 æ˜¯ä¸ºäº†åŒ…å«å½“å‰çª—å£å’Œå…¶å2ä¸ªçª—å£

    # ç¡®ä¿ç´¢å¼•ä¸è¶Šç•Œ
    plot_start_idx = max(0, plot_start_idx)
    plot_end_idx = min(len(df_raw), plot_end_idx)

    # æˆªå–ç”¨äºç»˜å›¾çš„DataFrame
    df_plot = df_raw.iloc[plot_start_idx:plot_end_idx].copy()
    # ä¸ºAltairå›¾è¡¨æ·»åŠ ä¸€ä¸ªæ—¶é—´æ­¥ï¼ˆæˆ–ç´¢å¼•ï¼‰åˆ—
    df_plot["Timestep"] = df_plot.index # ä½¿ç”¨åŸå§‹DataFrameçš„ç´¢å¼•ä½œä¸ºæ—¶é—´æ­¥

    with plot_placeholder.container():
        st.subheader("ä¼ æ„Ÿå™¨ç‰¹å¾ (å½“å‰çª—å£åŠé™„è¿‘æ•°æ®)")
        for feat in feature_cols_for_plot:
            if feat not in df_plot.columns: # ç¡®ä¿ç‰¹å¾åˆ—å­˜åœ¨äºå½“å‰DataFrameä¸­
                continue
            
            # ä¸ºæ¯ä¸ªç‰¹å¾åˆ›å»ºå›¾è¡¨
            # ä½¿ç”¨ melt æ“ä½œå°†å¤šåˆ—è½¬æ¢ä¸ºé•¿æ ¼å¼ï¼Œæ–¹ä¾¿ Altair ç»˜å›¾
            # æ³¨æ„: å¦‚æœåªç»˜åˆ¶ä¸€ä¸ªç‰¹å¾ï¼Œç›´æ¥ä¼ é€’å³å¯
            
            # åˆ›å»ºä¸€ä¸ªä¸´æ—¶çš„DataFrameç”¨äºå½“å‰ç‰¹å¾çš„ç»˜å›¾
            df_feat_plot = df_plot[[feat]].copy()
            df_feat_plot.index = df_plot["Timestep"] # å°†Timestepè®¾ç½®ä¸ºç´¢å¼•ä»¥ä¾¿é‡ç½®
            df_feat_plot = df_feat_plot.reset_index().rename(columns={feat: "Value"})

            chart = alt.Chart(df_feat_plot).mark_line().encode(
                x=alt.X("Timestep:Q", title="æ—¶é—´æ­¥ (é‡‡æ ·ç‚¹)"), # æ˜ç¡®æ˜¯é‡‡æ ·ç‚¹
                y=alt.Y("Value:Q", title="æ•°å€¼")
            ).properties(
                title=f"ç‰¹å¾: {feat}",
            ).interactive() # æ·»åŠ äº¤äº’æ€§ï¼Œå¦‚ç¼©æ”¾å’Œæ‹–åŠ¨
            st.altair_chart(chart, use_container_width=True) # è®©å›¾è¡¨å®½åº¦è‡ªé€‚åº”å®¹å™¨

    # æ¯æ¬¡æ»‘çª—å¤„ç†åæš‚åœï¼Œæ¨¡æ‹Ÿå®æ—¶å¤„ç†
    time.sleep(SIMULATION_INTERVAL_SECONDS)

# æ¨¡æ‹Ÿç»“æŸåï¼Œæœ€ç»ˆçŠ¶æ€
status_placeholder.header("ğŸ æ¨¡æ‹Ÿç»“æŸ")
st.success(f"æ‰€æœ‰æ ·æœ¬å¤„ç†å®Œæ¯•ï¼æœ€ç»ˆå‡†ç¡®ç‡ï¼š{acc:.2f} %")